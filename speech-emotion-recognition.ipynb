{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Emotion Recognition\n",
    "\n",
    "Speech Emotion Recognition (SER) is a manner of detecting the speaker's emotional state from the speech signal. Any computer system with limited processing resources may be programmed to sense or generate the few universal feelings, like Neutral, Anger, Happiness, and Sadness as needed.\n",
    "\n",
    "## Various applications\n",
    " \n",
    "Among other verticals that can benefit from this technology are as follows.\n",
    " \n",
    "* **Tele-consultation and health prediction**: AI model for social service agencies, hospitals and healthcare institutions can identify tell-tale signs for pre-stroke and epilepsy. It can also be a tool for occupational therapy for health prediction, identifying signs of non-motor stage 1/2/3 symptoms for depression, anxiety and/or cognitive decline.\n",
    " \n",
    "* **Education and HR**: Opsis solution can use different emotions and eye tracking to inform of students’ attention level and assist teachers in adjusting content or teaching methods and detecting learning disabilities. HR recruiting on emotion psychosomatic assessment benefit from unconscious bias removal, especially in large-scale recruiting.\n",
    " \n",
    "* **Public safety to analyze sentiment**: With regard to security, the solution provides real-time information on crowd mood, emergency control and risk management. Detecting persons of interest/suspicious characters and providing early warning signals can be achieved by the solution, which helps identify the coalescence of aggressive groups and detect the likelihood of their violent behavior – detecting the “true” inner state (lack of empathy, guilt, shame) sheds light on individuals’ likelihood to commit crime.\n",
    "\n",
    "## Datasets used\n",
    "\n",
    "### 1. Ravdess Dataframe\n",
    "Here is the filename identifiers as per the official RAVDESS website:\n",
    "\n",
    "* Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "* Vocal channel (01 = speech, 02 = song).\n",
    "* Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "* Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "* Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "* Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "* Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "\n",
    "### 2. CREMA Dataset\n",
    "* Data set of 7,442 original clips from 91 actors. These clips were from 48 male and 43 female actors between the ages of 20 and 74 coming from a variety of races and ethnicities (African America, Asian, Caucasian, Hispanic, and Unspecified).\n",
    "* Actors spoke from a selection of 12 sentences. The sentences were presented using one of six different emotions (Anger, Disgust, Fear, Happy, Neutral, and Sad) and four different emotion levels (Low, Medium, High, and Unspecified).\n",
    "\n",
    "### 3. TESS Dataset\n",
    "* There are a set of 200 target words were spoken in the carrier phrase \"Say the word _' by two actresses (aged 26 and 64 years) and recordings were made of the set portraying each of seven emotions (anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral).\n",
    "* There are 2800 data points (audio files) in total.\n",
    "* The dataset is organised such that each of the two female actor and their emotions are contain within its own folder. And within that, all 200 target words audio file can be found. The format of the audio file is a WAV format\n",
    "\n",
    "### 4. SAVEE Dataset\n",
    "The SAVEE database was recorded from four native English male speakers (identified as DC, JE, JK, KL), postgraduate students and researchers at the University of Surrey aged from 27 to 31 years. Emotion has been described psychologically in discrete categories: anger, disgust, fear, happiness, sadness and surprise\n",
    "\n",
    "Content\n",
    "This results in a total of 120 utterances per speaker, for example:\n",
    "\n",
    "* Common: She had your dark suit in greasy wash water all year.\n",
    "* Anger: Who authorized the unlimited expense account?\n",
    "* Disgust: Please take this dirty table cloth to the cleaners for me.\n",
    "* Fear: Call an ambulance for medical assistance.\n",
    "* Happiness: Those musicians harmonize marvelously.\n",
    "* Sadness: The prospect of cutting back spending is an unpleasant one for any governor.\n",
    "* Surprise: The carpet cleaners shampooed our oriental rug.\n",
    "* Neutral: The best way to learn is to solve extra problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import tensorflow as tf \n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y libsndfile1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Ravdess Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\n",
    "ravdess_directory_list = os.listdir(ravdess)\n",
    "print(ravdess_directory_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crema = \"/kaggle/input/cremad/AudioWAV/\"\n",
    "Tess = \"/kaggle/input/toronto-emotional-speech-set-tess/tess toronto emotional speech set data/TESS Toronto emotional speech set data/\"\n",
    "Savee = \"/kaggle/input/surrey-audiovisual-expressed-emotion-savee/ALL/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ravdees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_emotion = []\n",
    "file_path = []\n",
    "for i in ravdess_directory_list:\n",
    "    # as their are 24 different actors in our previous directory we need to extract files for each actor.\n",
    "    actor = os.listdir(ravdess + i)\n",
    "    for f in actor:\n",
    "        part = f.split('.')[0].split('-')\n",
    "    # third part in each file represents the emotion associated to that file.\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append(ravdess + i + '/' + f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actor[0])\n",
    "print(part[0])\n",
    "print(file_path[0])\n",
    "print(int(part[2]))\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "\n",
    "ravdess_df.Emotions.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust',\n",
    "                             8:'surprise'},\n",
    "                            inplace=True)\n",
    "print(ravdess_df.head())\n",
    "print(\"______________________________________________\")\n",
    "print(ravdess_df.tail())\n",
    "print(\"_______________________________________________\")\n",
    "print(ravdess_df.Emotions.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Crema DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    file_path.append(Crema + file)\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "        \n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Crema_df.head()\n",
    "print(Crema_df.Emotions.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TESS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + dir)\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part=='ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "        file_path.append(Tess + dir + '/' + file)\n",
    "\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Tess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Tess_df.head()\n",
    "print(Tess_df.Emotions.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SAVEE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savee_directory_list = os.listdir(Savee)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in savee_directory_list:\n",
    "    file_path.append(Savee + file)\n",
    "    part = file.split('_')[1]\n",
    "    ele = part[:-6]\n",
    "    if ele=='a':\n",
    "        file_emotion.append('angry')\n",
    "    elif ele=='d':\n",
    "        file_emotion.append('disgust')\n",
    "    elif ele=='f':\n",
    "        file_emotion.append('fear')\n",
    "    elif ele=='h':\n",
    "        file_emotion.append('happy')\n",
    "    elif ele=='n':\n",
    "        file_emotion.append('neutral')\n",
    "    elif ele=='sa':\n",
    "        file_emotion.append('sad')\n",
    "    else:\n",
    "        file_emotion.append('surprise')\n",
    "\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Savee_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Savee_df.head()\n",
    "print(Savee_df.Emotions.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrartion the 4 different dataset into one.\n",
    "data_path = pd.concat([ravdess_df, Crema_df, Tess_df, Savee_df], axis = 0)\n",
    "data_path.to_csv(\"data_path.csv\",index=False)\n",
    "data_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_path.Emotions.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.title('Count of Emotions', size=16)\n",
    "sns.countplot(data_path.Emotions)\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,sr = librosa.load(file_path[0])\n",
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE LOG MEL SPECTROGRAM\n",
    "plt.figure(figsize=(10, 5))\n",
    "spectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000) \n",
    "log_spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(log_spectrogram, y_axis='mel', sr=sr, x_axis='time');\n",
    "plt.title('Mel Spectrogram ')\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=30)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar()\n",
    "\n",
    "ipd.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOISE\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "# STRETCH\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "# SHIFT\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "# PITCH\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMAL AUDIO\n",
    "\n",
    "import librosa.display\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=data, sr=sr)\n",
    "ipd.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUDIO WITH NOISE\n",
    "x = noise(data)\n",
    "plt.figure(figsize=(12,5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRETCHED AUDIO\n",
    "x = stretch(data)\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHIFTED AUDIO\n",
    "x = shift(data)\n",
    "plt.figure(figsize=(12,5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUDIO WITH PITCH\n",
    "x = pitch(data, sr)\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcr(data,frame_length,hop_length):\n",
    "    zcr=librosa.feature.zero_crossing_rate(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "def rmse(data,frame_length=2048,hop_length=512):\n",
    "    rmse=librosa.feature.rms(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "def mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n",
    "    mfcc=librosa.feature.mfcc(data,sr=sr)\n",
    "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "def extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n",
    "    result=np.array([])\n",
    "    \n",
    "    result=np.hstack((result,\n",
    "                      zcr(data,frame_length,hop_length),\n",
    "                      rmse(data,frame_length,hop_length),\n",
    "                      mfcc(data,sr,frame_length,hop_length)\n",
    "                     ))\n",
    "    return result\n",
    "\n",
    "def get_features(path,duration=2.5, offset=0.6):\n",
    "    data,sr=librosa.load(path,duration=duration,offset=offset)\n",
    "    aud=extract_features(data)\n",
    "    audio=np.array(aud)\n",
    "    \n",
    "    noised_audio=noise(data)\n",
    "    aud2=extract_features(noised_audio)\n",
    "    audio=np.vstack((audio,aud2))\n",
    "    \n",
    "    pitched_audio=pitch(data,sr)\n",
    "    aud3=extract_features(pitched_audio)\n",
    "    audio=np.vstack((audio,aud3))\n",
    "    \n",
    "    pitched_audio1=pitch(data,sr)\n",
    "    pitched_noised_audio=noise(pitched_audio1)\n",
    "    aud4=extract_features(pitched_noised_audio)\n",
    "    audio=np.vstack((audio,aud4))\n",
    "    \n",
    "    return audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from tqdm import tqdm\n",
    "start = timeit.default_timer()\n",
    "X,Y=[],[]\n",
    "for path,emotion,index in tqdm (zip(data_path.Path,data_path.Emotions,range(data_path.Path.shape[0]))):\n",
    "    features=get_features(path)\n",
    "    if index%500==0:\n",
    "        print(f'{index} audio has been processed')\n",
    "    for i in features:\n",
    "        X.append(i)\n",
    "        Y.append(emotion)\n",
    "print('Done')\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(Y), data_path.Path.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emotions = pd.DataFrame(X)\n",
    "Emotions['Emotions'] = Y\n",
    "Emotions.to_csv('emotion.csv', index=False)\n",
    "Emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T14:12:39.845764Z",
     "iopub.status.busy": "2023-07-01T14:12:39.844437Z",
     "iopub.status.idle": "2023-07-01T14:13:11.793086Z",
     "shell.execute_reply": "2023-07-01T14:13:11.791894Z",
     "shell.execute_reply.started": "2023-07-01T14:12:39.845719Z"
    }
   },
   "outputs": [],
   "source": [
    "Emotions = pd.read_csv('./emotion.csv')\n",
    "Emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T14:13:20.478782Z",
     "iopub.status.busy": "2023-07-01T14:13:20.478364Z",
     "iopub.status.idle": "2023-07-01T14:13:20.591283Z",
     "shell.execute_reply": "2023-07-01T14:13:20.59011Z",
     "shell.execute_reply.started": "2023-07-01T14:13:20.478748Z"
    }
   },
   "outputs": [],
   "source": [
    "print(Emotions.isna().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T14:14:12.849527Z",
     "iopub.status.busy": "2023-07-01T14:14:12.849004Z",
     "iopub.status.idle": "2023-07-01T14:14:13.644166Z",
     "shell.execute_reply": "2023-07-01T14:14:13.643133Z",
     "shell.execute_reply.started": "2023-07-01T14:14:12.849485Z"
    }
   },
   "outputs": [],
   "source": [
    "Emotions=Emotions.fillna(0)\n",
    "print(Emotions.isna().any())\n",
    "Emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T14:15:14.792542Z",
     "iopub.status.busy": "2023-07-01T14:15:14.791887Z",
     "iopub.status.idle": "2023-07-01T14:15:15.065121Z",
     "shell.execute_reply": "2023-07-01T14:15:15.06103Z",
     "shell.execute_reply.started": "2023-07-01T14:15:14.792504Z"
    }
   },
   "outputs": [],
   "source": [
    "np.sum(Emotions.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T14:15:24.798163Z",
     "iopub.status.busy": "2023-07-01T14:15:24.797611Z",
     "iopub.status.idle": "2023-07-01T14:15:25.07167Z",
     "shell.execute_reply": "2023-07-01T14:15:25.07014Z",
     "shell.execute_reply.started": "2023-07-01T14:15:24.798128Z"
    }
   },
   "outputs": [],
   "source": [
    "#taking all rows and all cols without last col for X which include features\n",
    "#taking last col for Y, which include the emotions\n",
    "\n",
    "X = Emotions.iloc[: ,:-1].values\n",
    "Y = Emotions['Emotions'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T14:15:27.983302Z",
     "iopub.status.busy": "2023-07-01T14:15:27.982903Z",
     "iopub.status.idle": "2023-07-01T14:15:28.010889Z",
     "shell.execute_reply": "2023-07-01T14:15:28.009953Z",
     "shell.execute_reply.started": "2023-07-01T14:15:27.983269Z"
    }
   },
   "outputs": [],
   "source": [
    "# As this is a multiclass classification problem onehotencoding our Y\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T14:15:31.349601Z",
     "iopub.status.busy": "2023-07-01T14:15:31.349185Z",
     "iopub.status.idle": "2023-07-01T14:15:31.360147Z",
     "shell.execute_reply": "2023-07-01T14:15:31.359008Z",
     "shell.execute_reply.started": "2023-07-01T14:15:31.349544Z"
    }
   },
   "outputs": [],
   "source": [
    "print(Y.shape)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T14:15:38.350324Z",
     "iopub.status.busy": "2023-07-01T14:15:38.349555Z",
     "iopub.status.idle": "2023-07-01T14:15:39.851001Z",
     "shell.execute_reply": "2023-07-01T14:15:39.849048Z",
     "shell.execute_reply.started": "2023-07-01T14:15:38.350288Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=42,test_size=0.2, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T14:15:50.559638Z",
     "iopub.status.busy": "2023-07-01T14:15:50.558408Z",
     "iopub.status.idle": "2023-07-01T14:15:50.566028Z",
     "shell.execute_reply": "2023-07-01T14:15:50.56481Z",
     "shell.execute_reply.started": "2023-07-01T14:15:50.559554Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape Train and Test data for LSTM\n",
    "X_train = x_train.reshape(x_train.shape[0] , x_train.shape[1] , 1)\n",
    "X_test = x_test.reshape(x_test.shape[0] , x_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T14:15:54.922899Z",
     "iopub.status.busy": "2023-07-01T14:15:54.922397Z",
     "iopub.status.idle": "2023-07-01T14:15:56.412083Z",
     "shell.execute_reply": "2023-07-01T14:15:56.410934Z",
     "shell.execute_reply.started": "2023-07-01T14:15:54.922861Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T14:15:58.195057Z",
     "iopub.status.busy": "2023-07-01T14:15:58.194656Z",
     "iopub.status.idle": "2023-07-01T14:15:58.203537Z",
     "shell.execute_reply": "2023-07-01T14:15:58.202326Z",
     "shell.execute_reply.started": "2023-07-01T14:15:58.195024Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM,BatchNormalization , GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying early stopping for all models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T15:29:27.39179Z",
     "iopub.status.busy": "2023-07-01T15:29:27.391353Z",
     "iopub.status.idle": "2023-07-01T15:29:27.397433Z",
     "shell.execute_reply": "2023-07-01T15:29:27.396158Z",
     "shell.execute_reply.started": "2023-07-01T15:29:27.391755Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "model_checkpoint = ModelCheckpoint('best_model1_weights.h5', monitor='val_accuracy', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T15:29:29.545573Z",
     "iopub.status.busy": "2023-07-01T15:29:29.544486Z",
     "iopub.status.idle": "2023-07-01T15:29:29.551708Z",
     "shell.execute_reply": "2023-07-01T15:29:29.550469Z",
     "shell.execute_reply.started": "2023-07-01T15:29:29.545519Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stop=EarlyStopping(monitor='val_acc',mode='auto',patience=5,restore_best_weights=True)\n",
    "lr_reduction=ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.5,min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T14:16:07.244247Z",
     "iopub.status.busy": "2023-07-01T14:16:07.243845Z",
     "iopub.status.idle": "2023-07-01T14:16:09.948738Z",
     "shell.execute_reply": "2023-07-01T14:16:09.947551Z",
     "shell.execute_reply.started": "2023-07-01T14:16:07.244214Z"
    }
   },
   "outputs": [],
   "source": [
    "model01=Sequential()\n",
    "model01.add(LSTM(128,return_sequences=True,input_shape=(x_train.shape[1],1)))\n",
    "model01.add(Dropout(0.2))\n",
    "model01.add(LSTM(128,return_sequences=True))\n",
    "#model01.add(Dropout(0.2))\n",
    "model01.add(LSTM(128,return_sequences=True))\n",
    "#model01.add(Dropout(0.2))\n",
    "model01.add(LSTM(128,return_sequences=True))\n",
    "#model01.add(Dropout(0.2))\n",
    "model01.add(LSTM(128,return_sequences=True))\n",
    "#model01.add(Dropout(0.2))\n",
    "model01.add(LSTM(128,return_sequences=True))\n",
    "#model01.add(Dropout(0.3))\n",
    "model01.add(LSTM(128))\n",
    "#model01.add(Dropout(0.3))\n",
    "model01.add(Dense(7,activation = 'softmax'))\n",
    "model01.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model01.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T14:16:13.028541Z",
     "iopub.status.busy": "2023-07-01T14:16:13.027466Z",
     "iopub.status.idle": "2023-07-01T14:16:34.727976Z",
     "shell.execute_reply": "2023-07-01T14:16:34.726504Z",
     "shell.execute_reply.started": "2023-07-01T14:16:13.028502Z"
    }
   },
   "outputs": [],
   "source": [
    "hist=model01.fit(X_train, y_train,\n",
    "            epochs=20,\n",
    "            validation_data=(X_test, y_test),batch_size=64,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of our model on test data : \" , model01.evaluate(X_test,y_test)[1]*100 , \"%\")\n",
    "epochs = [i for i in range(20)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = hist.history['accuracy']\n",
    "train_loss = hist.history['loss']\n",
    "test_acc = hist.history['val_accuracy']\n",
    "test_loss = hist.history['val_loss']\n",
    "\n",
    "fig.set_size_inches(20,6)\n",
    "ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
    "ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
    "ax[0].set_title('Training & Testing Loss')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
    "ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
    "ax[1].set_title('Training & Testing Accuracy')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T14:16:39.774859Z",
     "iopub.status.busy": "2023-07-01T14:16:39.773793Z",
     "iopub.status.idle": "2023-07-01T14:16:39.783285Z",
     "shell.execute_reply": "2023-07-01T14:16:39.782276Z",
     "shell.execute_reply.started": "2023-07-01T14:16:39.77481Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape for CNN_LSTM MODEL\n",
    "x_traincnn =np.expand_dims(x_train, axis=2)\n",
    "x_testcnn= np.expand_dims(x_test, axis=2)\n",
    "x_traincnn.shape, y_train.shape, x_testcnn.shape, y_test.shape\n",
    "#x_testcnn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T15:32:14.957331Z",
     "iopub.status.busy": "2023-07-01T15:32:14.956885Z",
     "iopub.status.idle": "2023-07-01T15:32:15.16189Z",
     "shell.execute_reply": "2023-07-01T15:32:15.160802Z",
     "shell.execute_reply.started": "2023-07-01T15:32:14.957295Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as L\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    L.Conv1D(512,kernel_size=5, strides=1,padding='same', activation='relu',input_shape=(X_train.shape[1],1)),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
    "    \n",
    "    L.Conv1D(512,kernel_size=5,strides=1,padding='same',activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
    "    Dropout(0.2),  # Add dropout layer after the second max pooling layer\n",
    "    \n",
    "    L.Conv1D(256,kernel_size=5,strides=1,padding='same',activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
    "    \n",
    "    L.Conv1D(256,kernel_size=3,strides=1,padding='same',activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
    "    Dropout(0.2),  # Add dropout layer after the fourth max pooling layer\n",
    "    \n",
    "    L.Conv1D(128,kernel_size=3,strides=1,padding='same',activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.MaxPool1D(pool_size=3,strides=2,padding='same'),\n",
    "    Dropout(0.2),  # Add dropout layer after the fifth max pooling layer\n",
    "    \n",
    "    L.Flatten(),\n",
    "    L.Dense(512,activation='relu'),\n",
    "    L.BatchNormalization(),\n",
    "    L.Dense(7,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T15:32:35.072523Z",
     "iopub.status.busy": "2023-07-01T15:32:35.07213Z",
     "iopub.status.idle": "2023-07-01T17:27:18.409989Z",
     "shell.execute_reply": "2023-07-01T17:27:18.408827Z",
     "shell.execute_reply.started": "2023-07-01T15:32:35.072489Z"
    }
   },
   "outputs": [],
   "source": [
    "history=model.fit(x_traincnn, y_train, epochs=50, validation_data=(x_testcnn, y_test), batch_size=64,callbacks=[early_stop,lr_reduction,model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T17:28:04.122599Z",
     "iopub.status.busy": "2023-07-01T17:28:04.121872Z",
     "iopub.status.idle": "2023-07-01T17:28:12.073531Z",
     "shell.execute_reply": "2023-07-01T17:28:12.072495Z",
     "shell.execute_reply.started": "2023-07-01T17:28:04.122537Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy of our model on test data : \" , model.evaluate(x_testcnn,y_test)[1]*100 , \"%\")\n",
    "\n",
    "epochs = [i for i in range(50)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "test_acc = history.history['val_accuracy']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "fig.set_size_inches(20,6)\n",
    "ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
    "ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
    "ax[0].set_title('Training & Testing Loss')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
    "ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
    "ax[1].set_title('Training & Testing Accuracy')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T17:30:51.043307Z",
     "iopub.status.busy": "2023-07-01T17:30:51.042829Z",
     "iopub.status.idle": "2023-07-01T17:30:57.844806Z",
     "shell.execute_reply": "2023-07-01T17:30:57.843606Z",
     "shell.execute_reply.started": "2023-07-01T17:30:51.043272Z"
    }
   },
   "outputs": [],
   "source": [
    "# predicting on test data.\n",
    "pred_test0 = model.predict(x_testcnn)\n",
    "y_pred0 = encoder.inverse_transform(pred_test0)\n",
    "y_test0 = encoder.inverse_transform(y_test)\n",
    "\n",
    "# Check for random predictions\n",
    "df0 = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df0['Predicted Labels'] = y_pred0.flatten()\n",
    "df0['Actual Labels'] = y_test0.flatten()\n",
    "\n",
    "df0.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T17:31:10.18291Z",
     "iopub.status.busy": "2023-07-01T17:31:10.1825Z",
     "iopub.status.idle": "2023-07-01T17:31:10.198159Z",
     "shell.execute_reply": "2023-07-01T17:31:10.1971Z",
     "shell.execute_reply.started": "2023-07-01T17:31:10.182878Z"
    }
   },
   "outputs": [],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T17:31:55.292233Z",
     "iopub.status.busy": "2023-07-01T17:31:55.291417Z",
     "iopub.status.idle": "2023-07-01T17:31:56.273819Z",
     "shell.execute_reply": "2023-07-01T17:31:56.272713Z",
     "shell.execute_reply.started": "2023-07-01T17:31:55.292193Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(y_test0, y_pred0)\n",
    "plt.figure(figsize = (12, 10))\n",
    "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='.2f')\n",
    "plt.title('Confusion Matrix', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.show()\n",
    "print(classification_report(y_test0, y_pred0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T17:33:01.345546Z",
     "iopub.status.busy": "2023-07-01T17:33:01.344471Z",
     "iopub.status.idle": "2023-07-01T17:33:01.428663Z",
     "shell.execute_reply": "2023-07-01T17:33:01.427516Z",
     "shell.execute_reply.started": "2023-07-01T17:33:01.345505Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "model_json = model.to_json()\n",
    "with open(\"CNN_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"CNN_model_weights.h5\")\n",
    "print(\"Saved model to disk\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T17:35:04.565702Z",
     "iopub.status.busy": "2023-07-01T17:35:04.565263Z",
     "iopub.status.idle": "2023-07-01T17:35:04.81046Z",
     "shell.execute_reply": "2023-07-01T17:35:04.809402Z",
     "shell.execute_reply.started": "2023-07-01T17:35:04.565666Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "json_file = open('/kaggle/working/CNN_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"/kaggle/working/best_model1_weights.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T17:35:07.555111Z",
     "iopub.status.busy": "2023-07-01T17:35:07.554719Z",
     "iopub.status.idle": "2023-07-01T17:35:18.491122Z",
     "shell.execute_reply": "2023-07-01T17:35:18.489805Z",
     "shell.execute_reply.started": "2023-07-01T17:35:07.555077Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_testcnn,y_test)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading our Standard Scaler and encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T17:36:13.511327Z",
     "iopub.status.busy": "2023-07-01T17:36:13.510622Z",
     "iopub.status.idle": "2023-07-01T17:36:13.521214Z",
     "shell.execute_reply": "2023-07-01T17:36:13.52008Z",
     "shell.execute_reply.started": "2023-07-01T17:36:13.511288Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving scaler\n",
    "with open('scaler2.pickle', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Loading scaler\n",
    "with open('scaler2.pickle', 'rb') as f:\n",
    "    scaler2 = pickle.load(f)\n",
    "\n",
    "# Saving encoder\n",
    "with open('encoder2.pickle', 'wb') as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "# Loading encoder\n",
    "with open('encoder2.pickle', 'rb') as f:\n",
    "    encoder2 = pickle.load(f)\n",
    "\n",
    "    \n",
    "print(\"Done\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test script\n",
    "* That can predict new record "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T17:38:54.868425Z",
     "iopub.status.busy": "2023-07-01T17:38:54.867978Z",
     "iopub.status.idle": "2023-07-01T17:38:55.10981Z",
     "shell.execute_reply": "2023-07-01T17:38:55.10878Z",
     "shell.execute_reply.started": "2023-07-01T17:38:54.868391Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "json_file = open('/kaggle/working/CNN_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"/kaggle/working/best_model1_weights.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T17:39:16.289749Z",
     "iopub.status.busy": "2023-07-01T17:39:16.28933Z",
     "iopub.status.idle": "2023-07-01T17:39:16.297504Z",
     "shell.execute_reply": "2023-07-01T17:39:16.296484Z",
     "shell.execute_reply.started": "2023-07-01T17:39:16.289715Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/kaggle/working/scaler2.pickle', 'rb') as f:\n",
    "    scaler2 = pickle.load(f)\n",
    "    \n",
    "with open('/kaggle/working/encoder2.pickle', 'rb') as f:\n",
    "    encoder2 = pickle.load(f)\n",
    "\n",
    "    \n",
    "print(\"Done\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T17:39:19.313678Z",
     "iopub.status.busy": "2023-07-01T17:39:19.313258Z",
     "iopub.status.idle": "2023-07-01T17:39:19.318718Z",
     "shell.execute_reply": "2023-07-01T17:39:19.317546Z",
     "shell.execute_reply.started": "2023-07-01T17:39:19.313644Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T18:32:09.835927Z",
     "iopub.status.busy": "2023-07-01T18:32:09.835495Z",
     "iopub.status.idle": "2023-07-01T18:32:09.849153Z",
     "shell.execute_reply": "2023-07-01T18:32:09.848116Z",
     "shell.execute_reply.started": "2023-07-01T18:32:09.835893Z"
    }
   },
   "outputs": [],
   "source": [
    "def zcr(data,frame_length,hop_length):\n",
    "    zcr=librosa.feature.zero_crossing_rate(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "def rmse(data,frame_length=2048,hop_length=512):\n",
    "    rmse=librosa.feature.rms(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "def mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n",
    "    mfcc=librosa.feature.mfcc(data,sr=sr)\n",
    "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "def extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n",
    "    result=np.array([])\n",
    "    \n",
    "    result=np.hstack((result,\n",
    "                      zcr(data,frame_length,hop_length),\n",
    "                      rmse(data,frame_length,hop_length),\n",
    "                      mfcc(data,sr,frame_length,hop_length)\n",
    "                     ))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T18:32:12.239326Z",
     "iopub.status.busy": "2023-07-01T18:32:12.238453Z",
     "iopub.status.idle": "2023-07-01T18:32:12.246339Z",
     "shell.execute_reply": "2023-07-01T18:32:12.245151Z",
     "shell.execute_reply.started": "2023-07-01T18:32:12.239288Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_predict_feat(path):\n",
    "    d, s_rate= librosa.load(path, duration=2.5, offset=0.6)\n",
    "    res=extract_features(d)\n",
    "    result=np.array(res)\n",
    "    result=np.reshape(result,newshape=(1,2376))\n",
    "    i_result = scaler2.transform(result)\n",
    "    final_result=np.expand_dims(i_result, axis=2)\n",
    "    \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T18:32:13.947186Z",
     "iopub.status.busy": "2023-07-01T18:32:13.946415Z",
     "iopub.status.idle": "2023-07-01T18:32:14.048298Z",
     "shell.execute_reply": "2023-07-01T18:32:14.047226Z",
     "shell.execute_reply.started": "2023-07-01T18:32:13.947146Z"
    }
   },
   "outputs": [],
   "source": [
    "res=get_predict_feat(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-07-01-01-01-01.wav\")\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T18:32:16.801488Z",
     "iopub.status.busy": "2023-07-01T18:32:16.801094Z",
     "iopub.status.idle": "2023-07-01T18:32:16.808781Z",
     "shell.execute_reply": "2023-07-01T18:32:16.807611Z",
     "shell.execute_reply.started": "2023-07-01T18:32:16.801453Z"
    }
   },
   "outputs": [],
   "source": [
    "emotions1={1:'Neutral', 2:'Calm', 3:'Happy', 4:'Sad', 5:'Angry', 6:'Fear', 7:'Disgust',8:'Surprise'}\n",
    "def prediction(path1):\n",
    "    res=get_predict_feat(path1)\n",
    "    predictions=loaded_model.predict(res)\n",
    "    y_pred = encoder2.inverse_transform(predictions)\n",
    "    print(y_pred[0][0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T18:32:18.648537Z",
     "iopub.status.busy": "2023-07-01T18:32:18.648136Z",
     "iopub.status.idle": "2023-07-01T18:32:18.830837Z",
     "shell.execute_reply": "2023-07-01T18:32:18.829298Z",
     "shell.execute_reply.started": "2023-07-01T18:32:18.648504Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_02/03-01-01-01-01-01-02.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T18:07:12.254549Z",
     "iopub.status.busy": "2023-07-01T18:07:12.254147Z",
     "iopub.status.idle": "2023-07-01T18:07:12.449804Z",
     "shell.execute_reply": "2023-07-01T18:07:12.448646Z",
     "shell.execute_reply.started": "2023-07-01T18:07:12.254514Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-01-01-01-01-01.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T18:07:15.141628Z",
     "iopub.status.busy": "2023-07-01T18:07:15.141216Z",
     "iopub.status.idle": "2023-07-01T18:07:15.331916Z",
     "shell.execute_reply": "2023-07-01T18:07:15.330471Z",
     "shell.execute_reply.started": "2023-07-01T18:07:15.141591Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-05-01-02-02-01.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T18:07:17.923695Z",
     "iopub.status.busy": "2023-07-01T18:07:17.923269Z",
     "iopub.status.idle": "2023-07-01T18:07:18.113777Z",
     "shell.execute_reply": "2023-07-01T18:07:18.11064Z",
     "shell.execute_reply.started": "2023-07-01T18:07:17.923659Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_21/03-01-04-02-02-02-21.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T18:07:21.181416Z",
     "iopub.status.busy": "2023-07-01T18:07:21.181001Z",
     "iopub.status.idle": "2023-07-01T18:07:21.384602Z",
     "shell.execute_reply": "2023-07-01T18:07:21.383496Z",
     "shell.execute_reply.started": "2023-07-01T18:07:21.181374Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_02/03-01-06-01-02-02-02.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T18:31:04.207307Z",
     "iopub.status.busy": "2023-07-01T18:31:04.206834Z",
     "iopub.status.idle": "2023-07-01T18:31:04.403601Z",
     "shell.execute_reply": "2023-07-01T18:31:04.402235Z",
     "shell.execute_reply.started": "2023-07-01T18:31:04.207271Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-08-01-01-01-01.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T18:31:41.346289Z",
     "iopub.status.busy": "2023-07-01T18:31:41.345636Z",
     "iopub.status.idle": "2023-07-01T18:31:41.539252Z",
     "shell.execute_reply": "2023-07-01T18:31:41.537955Z",
     "shell.execute_reply.started": "2023-07-01T18:31:41.346249Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction(\"/kaggle/input/ravdess-emotional-speech-audio/Actor_01/03-01-07-01-01-01-01.wav\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 107620,
     "sourceId": 256618,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 316368,
     "sourceId": 639622,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 325566,
     "sourceId": 653195,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 338555,
     "sourceId": 671851,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3468263,
     "sourceId": 6060815,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30380,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
